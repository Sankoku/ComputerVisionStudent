from ultralytics import YOLO
import cv2
import numpy as np
import csv
from collections import deque, defaultdict
import time
import torch
import matplotlib.pyplot as plt

# ================== –ù–ê–õ–ê–®–¢–£–í–ê–ù–ù–Ø (–Ω–∞ –æ—Å–Ω–æ–≤—ñ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω—å) ==================
VIDEO_PATH = "video3.mp4"
MODEL_PATH = "yolov8m-pose.pt"
CONF = 0.3

# ===== –ù–û–í–Ü –ü–ê–†–ê–ú–ï–¢–†–ò =====
MAX_DURATION_MINUTES = 30  # –°–∫—ñ–ª—å–∫–∏ —Ö–≤–∏–ª–∏–Ω –æ–±—Ä–æ–±–ª—è—Ç–∏ (None = –≤—Å–µ –≤—ñ–¥–µ–æ)
SPEED_MULTIPLIER = 3      # –ü—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è: 1=normal, 2=2x —à–≤–∏–¥—à–µ, 3=3x —à–≤–∏–¥—à–µ
                          # –ü—Ä–∏ –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—ñ –æ–±—Ä–æ–±–ª—è—î—Ç—å—Å—è –∫–æ–∂–µ–Ω N-–π –∫–∞–¥—Ä
# ===========================

# GPU
device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
print(f"üîç Device: {device}")

# –ö–∞–ª—ñ–±—Ä—É–≤–∞–Ω–Ω—è baseline
BASELINE_FRAMES = 90  # ~3 —Å–µ–∫—É–Ω–¥–∏ –ø—Ä–∏ 30 FPS (–±—É–ª–æ 50)
EMA_ALPHA = 0.3  # –ó–≥–ª–∞–¥–∂—É–≤–∞–Ω–Ω—è

# –ü–æ—Ä–æ–≥–∏ —É–≤–∞–≥–∏ 
SCORE_ATTENTIVE = 0.70  # –£–≤–∞–∂–Ω–∏–π
SCORE_NEUTRAL = 0.50    # –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∏–π
SCORE_DISTRACTED = 0.30 # –í—ñ–¥–≤–æ–ª—ñ–∫—Å—è

# –ß–∞—Å–æ–≤—ñ –ø–æ—Ä–æ–≥–∏
INATTENTIVE_SECONDS = 3.0  # –°–∫—ñ–ª—å–∫–∏ —Å–µ–∫—É–Ω–¥ –Ω–µ—É–≤–∞–∂–Ω–æ—Å—Ç—ñ = –ø—Ä–æ–±–ª–µ–º–∞
HAND_RAISED_MIN_FRAMES = 15  # –ú—ñ–Ω—ñ–º—É–º –∫–∞–¥—Ä—ñ–≤ –∑ –ø—ñ–¥–Ω—è—Ç–æ—é —Ä—É–∫–æ—é
FPS = 30.0

# –¢—Ä–µ–∫—ñ–Ω–≥
IOU_MATCH_THRESH = 0.15 
MAX_MISSED_FRAMES = 150  # ~5 —Å–µ–∫—É–Ω–¥

# ================== –Ü–ù–Ü–¶–Ü–ê–õ–Ü–ó–ê–¶–Ü–Ø ==================
model = YOLO(MODEL_PATH)
model.to(device)

cap = cv2.VideoCapture(VIDEO_PATH)
if cap.get(cv2.CAP_PROP_FPS) > 0:
    FPS = cap.get(cv2.CAP_PROP_FPS)
w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

# –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤—ñ–¥–µ–æ
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter('output_scientific.mp4', fourcc, int(FPS), (w, h))

students = {}
next_id = 0
activity_log = []
frame_id = 0
processed_frames = 0  # –õ—ñ—á–∏–ª—å–Ω–∏–∫ –æ–±—Ä–æ–±–ª–µ–Ω–∏—Ö –∫–∞–¥—Ä—ñ–≤

# –û–±—á–∏—Å–ª—é—î–º–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–∞–¥—Ä—ñ–≤
max_frames = None
if MAX_DURATION_MINUTES is not None:
    max_frames = int(MAX_DURATION_MINUTES * 60 * FPS)

print(f"  Video: {w}x{h} @ {FPS:.1f} FPS")
print(f"  Baseline: {BASELINE_FRAMES} frames ({BASELINE_FRAMES/FPS:.1f}s)")
print(f"  IOU threshold: {IOU_MATCH_THRESH}")
print(f"  Duration limit: {MAX_DURATION_MINUTES} min" if MAX_DURATION_MINUTES else "‚è±Ô∏è  Duration: Full video")
print(f"  Speed multiplier: {SPEED_MULTIPLIER}x (processing every {SPEED_MULTIPLIER} frame)")
if max_frames:
    print(f" Will process ~{max_frames // SPEED_MULTIPLIER} frames total")

# ================== –§–£–ù–ö–¶–Ü–á ==================

def bbox_from_kp(kp):
    """–°—Ç–≤–æ—Ä—é—î bounding box –∑ keypoints"""
    x_min = int(np.min(kp[:,0]))
    x_max = int(np.max(kp[:,0]))
    y_min = int(np.min(kp[:,1]))
    y_max = int(np.max(kp[:,1]))
    return (x_min, y_min, x_max, y_max)

def iou(boxA, boxB):
    """Intersection over Union –¥–ª—è –º–∞—Ç—á—ñ–Ω–≥—É"""
    xA = max(boxA[0], boxB[0])
    yA = max(boxA[1], boxB[1])
    xB = min(boxA[2], boxB[2])
    yB = min(boxA[3], boxB[3])
    interW = max(0, xB - xA)
    interH = max(0, yB - yA)
    interArea = interW * interH
    boxAArea = max(1, (boxA[2]-boxA[0])*(boxA[3]-boxA[1]))
    boxBArea = max(1, (boxB[2]-boxB[0])*(boxB[3]-boxB[1]))
    return interArea / (boxAArea + boxBArea - interArea + 1e-9)

def match_detections(prev_students, det_bboxes, iou_thresh=IOU_MATCH_THRESH):
    """–ú–∞—Ç—á–∏—Ç—å –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ –¥–µ—Ç–µ–∫—Ü—ñ—ó –∑ –Ω–æ–≤–∏–º–∏"""
    matches = {}
    unmatched_prev = set(prev_students.keys())
    unmatched_det = set(range(len(det_bboxes)))
    ious = {}
    
    for pid, s in prev_students.items():
        for j, bbox in enumerate(det_bboxes):
            try:
                ious[(pid,j)] = iou(s['bbox'], bbox)
            except Exception:
                ious[(pid,j)] = 0.0
    
    # Greedy matching
    while ious:
        (pid,j), best = max(ious.items(), key=lambda x: x[1])
        if best < iou_thresh:
            break
        matches[pid] = j
        unmatched_prev.discard(pid)
        unmatched_det.discard(j)
        keys_to_del = [k for k in ious if k[0]==pid or k[1]==j]
        for k in keys_to_del:
            del ious[k]
    
    return matches, unmatched_prev, unmatched_det

def eye_aspect_ratio(eye_points):
    """
    EAR (Eye Aspect Ratio) - –¥–ª—è –¥–µ—Ç–µ–∫—Ü—ñ—ó –∑–∞–∫—Ä–∏—Ç–∏—Ö –æ—á–µ–π
    –ù–∞ –æ—Å–Ω–æ–≤—ñ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω—å Soukupov√° and ƒåech (2016)
    """
    if eye_points.shape[0] < 2:
        return 1.0
    # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞ –≤—ñ–¥—Å—Ç–∞–Ω—å –º—ñ–∂ —Ç–æ—á–∫–∞–º–∏ –æ–∫–∞
    vertical = np.linalg.norm(eye_points[0] - eye_points[1])
    # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∞ –≤—ñ–¥—Å—Ç–∞–Ω—å
    horizontal = np.linalg.norm(eye_points[0] - eye_points[-1]) + 1e-6
    ear = vertical / horizontal
    return ear

def compute_features(kp):
    """
    –û–±—á–∏—Å–ª—é—î —Ä–æ–∑—à–∏—Ä–µ–Ω–∏–π –Ω–∞–±—ñ—Ä features –Ω–∞ –æ—Å–Ω–æ–≤—ñ –Ω–∞—É–∫–æ–≤–∏—Ö –¥–æ—Å–ª—ñ–¥–∂–µ–Ω—å:
    - Head pose (pitch, yaw)
    - Hand position
    - Body posture
    - Eye aspect ratio (–¥–ª—è –≤—Ç–æ–º–∏/—Å–Ω—É)
    """
    if kp is None or kp.shape[0] < 13:
        return None
    
    # Keypoints COCO format
    nose = kp[0]
    left_eye = kp[1]
    right_eye = kp[2]
    left_ear = kp[3]
    right_ear = kp[4]
    left_shoulder = kp[5]
    right_shoulder = kp[6]
    left_elbow = kp[7]
    right_elbow = kp[8]
    left_wrist = kp[9]
    right_wrist = kp[10]
    left_hip = kp[11]
    right_hip = kp[12]
    
    # –ë–∞–∑–æ–≤—ñ —Ç–æ—á–∫–∏
    mid_shoulder = (left_shoulder + right_shoulder) / 2.0
    mid_hip = (left_hip + right_hip) / 2.0
    mid_eyes = (left_eye + right_eye) / 2.0
    
    # –î–æ–≤–∂–∏–Ω–∞ —Ç–æ—Ä—Å—É –¥–ª—è –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó
    torso_len = np.linalg.norm(mid_shoulder - mid_hip) + 1e-6
    
    # 1. HEAD POSE (–∫–ª—é—á–æ–≤–∏–π —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä –∑–∞ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è–º–∏)
    head_pitch = float((nose[1] - mid_shoulder[1]) / torso_len)  # –ù–∞—Ö–∏–ª –≤–ø–µ—Ä–µ–¥/–Ω–∞–∑–∞–¥
    head_yaw = float((nose[0] - mid_eyes[0]) / torso_len)  # –ü–æ–≤–æ—Ä–æ—Ç –≤–ª—ñ–≤–æ/–≤–ø—Ä–∞–≤–æ
    
    # 2. EYE ASPECT RATIO (–¥–ª—è –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∑–∞–∫—Ä–∏—Ç–∏—Ö –æ—á–µ–π)
    # –°–ø—Ä–æ—â–µ–Ω–∞ –≤–µ—Ä—Å—ñ—è - –≤—ñ–¥—Å—Ç–∞–Ω—å –º—ñ–∂ –æ—á–∏–º–∞ —Ç–∞ –Ω–æ—Å–æ–º
    eye_openness = float(np.linalg.norm(mid_eyes - nose) / torso_len)
    
    # 3. HAND POSITION ANALYSIS (–∑–∞ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è–º–∏ - –ø—ñ–¥–Ω—è—Ç—ñ —Ä—É–∫–∏ = –∞–∫—Ç–∏–≤–Ω–∞ —É—á–∞—Å—Ç—å)
    hands_up = float(
        (left_wrist[1] < left_shoulder[1] - 0.2*torso_len) or 
        (right_wrist[1] < right_shoulder[1] - 0.2*torso_len)
    )
    
    # –†—É–∫–∏ –≤–Ω–∏–∑—É (–º–æ–∂–ª–∏–≤–æ –Ω–∞ —Å—Ç–æ–ª—ñ –∞–±–æ —Ä–æ–∑—Å–ª–∞–±–ª–µ–Ω–∏–π)
    hands_below = float(
        (left_wrist[1] > mid_hip[1] + 0.1*torso_len) and 
        (right_wrist[1] > mid_hip[1] + 0.1*torso_len)
    )
    
    # –í—ñ–¥—Å—Ç–∞–Ω—å –º—ñ–∂ —Ä—É–∫–∞–º–∏ (–¥–ª—è –¥–µ—Ç–µ–∫—Ü—ñ—ó –∂–µ—Å—Ç–∏–∫—É–ª—è—Ü—ñ—ó)
    hands_distance = float(np.linalg.norm(left_wrist - right_wrist) / torso_len)
    
    # 4. BODY POSTURE (—Å—É—Ç—É–ª—ñ—Å—Ç—å/–≤—Ç–æ–º–∞)
    # –í—ñ–¥—Å—Ç–∞–Ω—å –º—ñ–∂ –≤—É—Ö–∞–º–∏ —Ç–∞ –ø–ª–µ—á–∏–º–∞ (—ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä —Å—É—Ç—É–ª–æ—Å—Ç—ñ)
    mid_ears = (left_ear + right_ear) / 2.0
    slouch_factor = float((mid_shoulder[1] - mid_ears[1]) / torso_len)
    
    # 5. MOVEMENT/ACTIVITY LEVEL
    # –ë—É–¥–µ –æ–±—á–∏—Å–ª—é–≤–∞—Ç–∏—Å—å –ø—Ä–∏ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—ñ –∑ baseline
    
    return {
        "head_pitch": head_pitch,
        "head_yaw": head_yaw,
        "eye_openness": eye_openness,
        "hands_up": hands_up,
        "hands_below": hands_below,
        "hands_distance": hands_distance,
        "slouch_factor": slouch_factor,
        "torso_len": torso_len
    }

def student_attention_score(features, baseline):
    """
    –ü–æ–∫—Ä–∞—â–µ–Ω–∞ —Ñ–æ—Ä–º—É–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω—å –ø—Ä–æ engagement detection
    
    –ë–∞–∑—É—î—Ç—å—Å—è –Ω–∞:
    - Canedo et al. (2018) - Head pose estimation
    - Whitehill et al. (2014) - Facial features for engagement
    - Raca et al. (2015) - Body language indicators
    """
    baseline = baseline or {}
    
    # –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è –≤—ñ–¥ baseline
    pitch_dev = features["head_pitch"] - baseline.get("head_pitch", 0.0)
    yaw_dev = abs(features["head_yaw"] - baseline.get("head_yaw", 0.0))
    
    hands_up = features["hands_up"]
    hands_below = features["hands_below"]
    eye_openness = features["eye_openness"]
    slouch_dev = features["slouch_factor"] - baseline.get("slouch_factor", 0.0)
    
    #Score components (–≤–∞–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω—å)
    score = 0.0
    
    # 1. –ü—ñ–¥–Ω—è—Ç—ñ —Ä—É–∫–∏ - —Å–∏–ª—å–Ω–∏–π –ø–æ–∑–∏—Ç–∏–≤–Ω–∏–π —Å–∏–≥–Ω–∞–ª (+2.0)
    score += 2.0 * hands_up
    
    # 2. –û—Ä—ñ—î–Ω—Ç–∞—Ü—ñ—è –≥–æ–ª–æ–≤–∏ (–Ω–∞–π–≤–∞–∂–ª–∏–≤—ñ—à–∏–π —Ñ–∞–∫—Ç–æ—Ä)
    # Pitch: –≥–æ–ª–æ–≤–∞ –¥–∏–≤–∏—Ç—å—Å—è –≤–≥–æ—Ä—É = –¥–æ–±—Ä–µ, –≤–Ω–∏–∑ = –ø–æ–≥–∞–Ω–æ
    score += 1.2 * max(0.0, 1.0 - abs(pitch_dev * 1.5))
    score -= 1.5 * max(0.0, pitch_dev * 1.0)  # –®—Ç—Ä–∞—Ñ –∑–∞ –Ω–∞—Ö–∏–ª –≤–Ω–∏–∑
    
    # Yaw: –≥–æ–ª–æ–≤–∞ –ø–æ–≤–µ—Ä–Ω—É—Ç–∞ –≤–±—ñ–∫ = –Ω–µ—É–≤–∞–∂–Ω—ñ—Å—Ç—å
    score -= 1.0 * min(1.0, yaw_dev * 2.0)
    
    # 3. –†—É–∫–∏ –≤–Ω–∏–∑—É - –º–æ–∂–ª–∏–≤–æ –≤—ñ–¥–≤–æ–ª—ñ–∫—Å—è –∞–±–æ –Ω–∞ —Ç–µ–ª–µ—Ñ–æ–Ω—ñ
    score -= 0.8 * hands_below
    
    # 4. –û—á—ñ (–∑–∞–∫—Ä–∏—Ç—ñ –∞–±–æ —Å–æ–Ω–Ω—ñ)
    baseline_eye = baseline.get("eye_openness", 0.5)
    if eye_openness < baseline_eye * 0.6:  # –û—á—ñ –º–∞–π–∂–µ –∑–∞–∫—Ä–∏—Ç—ñ
        score -= 1.5
    
    # 5. –°—É—Ç—É–ª—ñ—Å—Ç—å (–∑–º—ñ–Ω–∞ –ø–æ–∑–∏ –º–æ–∂–µ –æ–∑–Ω–∞—á–∞—Ç–∏ –≤—Ç–æ–º—É)
    if slouch_dev > 0.15:  # –°–∏–ª—å–Ω–∞ —Å—É—Ç—É–ª—ñ—Å—Ç—å –≤—ñ–¥–Ω–æ—Å–Ω–æ baseline
        score -= 0.7
    
    # Sigmoid –¥–ª—è –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó –≤ [0, 1]
    return float(1.0 / (1.0 + np.exp(-score)))

# ================== –û–°–ù–û–í–ù–ò–ô –¶–ò–ö–õ ==================
print("\n–ü–æ—á–∏–Ω–∞—î–º–æ –æ–±—Ä–æ–±–∫—É... (–ù–∞—Ç–∏—Å–Ω–∏ 'q' –¥–ª—è –∑—É–ø–∏–Ω–∫–∏)\n")
t0 = time.time()

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ª—ñ–º—ñ—Ç—É —á–∞—Å—É
    if max_frames is not None and frame_id >= max_frames:
        print(f"\n  –î–æ—Å—è–≥–Ω—É—Ç–æ –ª—ñ–º—ñ—Ç —á–∞—Å—É: {MAX_DURATION_MINUTES} —Ö–≤–∏–ª–∏–Ω")
        break
    
    # –ü—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è: –ø—Ä–æ–ø—É—Å–∫–∞—î–º–æ –∫–∞–¥—Ä–∏
    if frame_id % SPEED_MULTIPLIER != 0:
        frame_id += 1
        continue
    
    processed_frames += 1

    # YOLO –¥–µ—Ç–µ–∫—Ü—ñ—è –∑ GPU
    results = model(frame, conf=CONF, verbose=False, device=device)
    people = results[0].keypoints
    
    det_bboxes = []
    det_kps = []
    det_feats = []

    # –ó–±–∏—Ä–∞—î–º–æ –¥–µ—Ç–µ–∫—Ü—ñ—ó
    for p in people:
        kp = p.xy[0].cpu().numpy() if hasattr(p, 'xy') else None
        if kp is None or kp.shape[0] < 13:
            continue
        
        bbox = bbox_from_kp(kp)
        feats = compute_features(kp)
        if feats is None:
            continue
        
        det_bboxes.append(bbox)
        det_kps.append(kp)
        det_feats.append(feats)

    # Matching –∑ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ–º–∏ —Å—Ç—É–¥–µ–Ω—Ç–∞–º–∏
    matches, unmatched_prev, unmatched_det = match_detections(
        students, det_bboxes, IOU_MATCH_THRESH
    )
    
    updated_ids = set()

    # –û–Ω–æ–≤–ª—é—î–º–æ matched —Å—Ç—É–¥–µ–Ω—Ç—ñ–≤
    for pid, j in matches.items():
        kp = det_kps[j]
        bbox = det_bboxes[j]
        feats = det_feats[j]
        s = students[pid]

        s['bbox'] = bbox
        s['last_seen'] = frame_id

        # Baseline –∫–∞–ª—ñ–±—Ä—É–≤–∞–Ω–Ω—è
        if s['baseline_count'] < BASELINE_FRAMES:
            # –ê–∫—É–º—É–ª—é—î–º–æ features –¥–ª—è baseline
            for k in feats:
                s['baseline'][k] = (
                    s['baseline'][k] * s['baseline_count'] + feats[k]
                ) / (s['baseline_count'] + 1)
            s['baseline_count'] += 1
        else:
            # –û–±—á–∏—Å–ª—é—î–º–æ attention score
            base = s.get('baseline', {})
            raw_score = student_attention_score(feats, base)
            
            # EMA –∑–≥–ª–∞–¥–∂—É–≤–∞–Ω–Ω—è
            s['ema'] = EMA_ALPHA * raw_score + (1 - EMA_ALPHA) * s.get('ema', raw_score)
            
            # –Ü—Å—Ç–æ—Ä—ñ—è
            s.setdefault('history', deque(maxlen=int(FPS*10))).append(s['ema'])
            
            # –õ—ñ—á–∏–ª—å–Ω–∏–∫ –Ω–µ—É–≤–∞–∂–Ω–æ—Å—Ç—ñ
            if s['ema'] < SCORE_NEUTRAL:
                s['inattentive_frames'] += 1
            else:
                s['inattentive_frames'] = 0
            
            # –î–µ—Ç–µ–∫—Ü—ñ—è –ø—ñ–¥–Ω—è—Ç—Ç—è —Ä—É–∫–∏ (–∑ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—î—é)
            if feats['hands_up']:
                s['hand_raised_frames'] = s.get('hand_raised_frames', 0) + 1
            else:
                s['hand_raised_frames'] = 0

        updated_ids.add(pid)

        # –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Ø
        x1, y1, x2, y2 = bbox
        
        if s.get('baseline_count', 0) < BASELINE_FRAMES:
            # –ö–∞–ª—ñ–±—Ä—É–≤–∞–Ω–Ω—è
            color = (180, 180, 180)
            progress = int(100 * s['baseline_count'] / BASELINE_FRAMES)
            label = f"ID{pid}: Calibrating {progress}%"
        else:
            # –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è —É–≤–∞–≥–∏
            if s['ema'] >= SCORE_ATTENTIVE:
                color = (0, 255, 0)  # –ó–µ–ª–µ–Ω–∏–π - —É–≤–∞–∂–Ω–∏–π
                label = f"ID{pid}: Attentive {s['ema']:.2f}"
            elif s['ema'] >= SCORE_NEUTRAL:
                color = (0, 255, 255)  # –ñ–æ–≤—Ç–∏–π - –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∏–π
                label = f"ID{pid}: Neutral {s['ema']:.2f}"
            elif s['ema'] >= SCORE_DISTRACTED:
                color = (0, 165, 255)  # –ü–æ–º–∞—Ä–∞–Ω—á–µ–≤–∏–π - –≤—ñ–¥–≤–æ–ª—ñ–∫—Å—è
                label = f"ID{pid}: Distracted {s['ema']:.2f}"
            else:
                needed = int(INATTENTIVE_SECONDS * FPS)
                is_problem = s['inattentive_frames'] >= needed
                color = (0, 0, 255) if is_problem else (0, 100, 255)  # –ß–µ—Ä–≤–æ–Ω–∏–π
                label = f"ID{pid}: Inattentive {s['ema']:.2f}"
            
            # –Ü–Ω–¥–∏–∫–∞—Ü—ñ—è –ø—ñ–¥–Ω—è—Ç—Ç—è —Ä—É–∫–∏
            if s.get('hand_raised_frames', 0) >= HAND_RAISED_MIN_FRAMES:
                cv2.putText(frame, "HAND UP!", (x1, y1-30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
        cv2.putText(frame, label, (x1, max(0, y1-8)), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    # –°—Ç–≤–æ—Ä—é—î–º–æ –Ω–æ–≤–∏—Ö —Å—Ç—É–¥–µ–Ω—Ç—ñ–≤
    for j in unmatched_det:
        kp = det_kps[j]
        bbox = det_bboxes[j]
        feats = det_feats[j]
        
        pid = next_id
        next_id += 1
        
        students[pid] = {
            'bbox': bbox,
            'baseline': feats.copy(),
            'baseline_count': 1,
            'ema': 0.5,
            'history': deque(maxlen=int(FPS*10)),
            'inattentive_frames': 0,
            'hand_raised_frames': 0,
            'last_seen': frame_id
        }
        
        x1, y1, x2, y2 = bbox
        cv2.rectangle(frame, (x1, y1), (x2, y2), (200, 200, 0), 2)
        cv2.putText(frame, f"New ID{pid}", (x1, max(0, y1-8)), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 0), 2)

    # –í–∏–¥–∞–ª—è—î–º–æ —Å—Ç–∞—Ä—ñ —Ç—Ä–µ–∫–∏
    to_delete = []
    for pid, s in list(students.items()):
        if frame_id - s.get('last_seen', -99999) > MAX_MISSED_FRAMES:
            to_delete.append(pid)
    for pid in to_delete:
        del students[pid]

    # –ó–ê–ì–ê–õ–¨–ù–ê –°–¢–ê–¢–ò–°–¢–ò–ö–ê
    people_visible = len(det_bboxes)
    
    # –ü—ñ–¥—Ä–∞—Ö—É–Ω–æ–∫ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ—è—Ö (—Ç—ñ–ª—å–∫–∏ –ø—ñ—Å–ª—è –∫–∞–ª—ñ–±—Ä—É–≤–∞–Ω–Ω—è)
    calibrated = [s for s in students.values() if s.get('baseline_count', 0) >= BASELINE_FRAMES]
    
    attentive_cnt = sum(1 for s in calibrated if s.get('ema', 0) >= SCORE_ATTENTIVE)
    neutral_cnt = sum(1 for s in calibrated if SCORE_NEUTRAL <= s.get('ema', 0) < SCORE_ATTENTIVE)
    distracted_cnt = sum(1 for s in calibrated if SCORE_DISTRACTED <= s.get('ema', 0) < SCORE_NEUTRAL)
    inattentive_cnt = sum(1 for s in calibrated if s.get('ema', 0) < SCORE_DISTRACTED 
                         and s.get('inattentive_frames', 0) >= int(INATTENTIVE_SECONDS*FPS))
    
    hands_up_cnt = sum(1 for s in students.values() 
                       if s.get('hand_raised_frames', 0) >= HAND_RAISED_MIN_FRAMES)

    # –Ü–ù–î–ï–ö–° –£–í–ê–ì–ò –ö–õ–ê–°–£ (0-1)
    total = max(1, len(calibrated))
    attention_index = (
        attentive_cnt + 0.5 * neutral_cnt + 0.8 * hands_up_cnt - 0.5 * inattentive_cnt
    ) / total
    attention_index = max(0.0, min(1.0, attention_index))

    # OVERLAY –ü–ê–ù–ï–õ–¨
    overlay = frame.copy()
    cv2.rectangle(overlay, (10, 10), (550, 180), (0, 0, 0), -1)
    cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
    
    y_pos = 35
    cv2.putText(frame, f"Students: {people_visible}", (20, y_pos), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    y_pos += 30
    cv2.putText(frame, f"Attentive: {attentive_cnt} | Neutral: {neutral_cnt}", 
               (20, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    y_pos += 30
    cv2.putText(frame, f"Distracted: {distracted_cnt} | Inattentive: {inattentive_cnt}", 
               (20, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 165, 255), 2)
    y_pos += 30
    cv2.putText(frame, f"Hands up: {hands_up_cnt}", 
               (20, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    y_pos += 30
    
    # –Ü–Ω–¥–µ–∫—Å —É–≤–∞–≥–∏ –∑ –∫–æ–ª—å–æ—Ä–æ–º
    attn_color = (0, 255, 0) if attention_index > 0.7 else \
                 (0, 255, 255) if attention_index > 0.5 else (0, 0, 255)
    cv2.putText(frame, f"Class Attention Index: {attention_index:.2f}", 
               (20, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.7, attn_color, 2)

    # –õ–æ–≥
    current_time = frame_id / FPS  # –†–µ–∞–ª—å–Ω–∏–π —á–∞—Å —É –≤—ñ–¥–µ–æ
    activity_log.append({
        "frame": frame_id,
        "time_sec": round(current_time, 2),
        "visible": people_visible,
        "attentive": attentive_cnt,
        "neutral": neutral_cnt,
        "distracted": distracted_cnt,
        "inattentive": inattentive_cnt,
        "hands_up": hands_up_cnt,
        "attention_index": round(attention_index, 3)
    })

    cv2.imshow("Scientific Monitor", frame)
    out.write(frame)
    
    frame_id += 1
    
    # –ü—Ä–æ–≥—Ä–µ—Å –∫–æ–∂–Ω—ñ 60 –æ–±—Ä–æ–±–ª–µ–Ω–∏—Ö –∫–∞–¥—Ä—ñ–≤
    if processed_frames % 60 == 0:
        elapsed = time.time() - t0
        fps_actual = processed_frames / elapsed
        current_time = frame_id / FPS
        time_min = int(current_time // 60)
        time_sec = int(current_time % 60)
        print(f"‚è±Ô∏è  Frame {frame_id} ({time_min}:{time_sec:02d}) | "
              f"Processing: {fps_actual:.1f} FPS | "
              f"Students: {people_visible} | Attention: {attention_index:.2f}")
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
out.release()
cv2.destroyAllWindows()

# –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø CSV
with open("activity_scientific.csv", "w", newline="", encoding='utf-8') as f:
    fieldnames = ["frame", "time_sec", "visible", "attentive", "neutral", 
                  "distracted", "inattentive", "hands_up", "attention_index"]
    writer = csv.DictWriter(f, fieldnames=fieldnames)
    writer.writeheader()
    writer.writerows(activity_log)

print("\n –ó–∞–≤–µ—Ä—à–µ–Ω–æ!")
print(f" –û–±—Ä–æ–±–ª–µ–Ω–æ {processed_frames} –∫–∞–¥—Ä—ñ–≤ (–∑ {frame_id} —É –≤—ñ–¥–µ–æ) –∑–∞ {time.time()-t0:.1f}—Å")
print(f" –†–µ–∞–ª—å–Ω–∞ —à–≤–∏–¥–∫—ñ—Å—Ç—å –æ–±—Ä–æ–±–∫–∏: {processed_frames/(time.time()-t0):.1f} FPS")
print(f"  –ü—Ä–æ–∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–æ {frame_id/FPS/60:.1f} —Ö–≤–∏–ª–∏–Ω –≤—ñ–¥–µ–æ")
print("  –ó–±–µ—Ä–µ–∂–µ–Ω–æ: activity_scientific.csv, output_scientific.mp4")

# ===== –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ò =====
if len(activity_log) > 0:
    print("\n –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤...")

    times = [d['time_sec'] for d in activity_log]
    visible = [d['visible'] for d in activity_log]
    attentive = [d['attentive'] for d in activity_log]
    neutral = [d['neutral'] for d in activity_log]
    distracted = [d['distracted'] for d in activity_log]
    inattentive = [d['inattentive'] for d in activity_log]
    hands_up = [d['hands_up'] for d in activity_log]
    attention_index = [d['attention_index'] for d in activity_log]

    # –°—Ç–≤–æ—Ä—é—î–º–æ —Ñ—ñ–≥—É—Ä—É –∑ 6 –≥—Ä–∞—Ñ—ñ–∫–∞–º–∏ (2x3)
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    fig.suptitle('–ù–∞—É–∫–æ–≤–∏–π –∞–Ω–∞–ª—ñ–∑ –Ω–∞–≤—á–∞–ª—å–Ω–æ—ó –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ —É—á–Ω—ñ–≤', 
                 fontsize=16, fontweight='bold')

    # –ì—Ä–∞—Ñ—ñ–∫ 1: –ö—ñ–ª—å–∫—ñ—Å—Ç—å —É—á–Ω—ñ–≤
    axes[0, 0].plot(times, visible, color='blue', linewidth=2, marker='o', markersize=2)
    axes[0, 0].set_title('–ö—ñ–ª—å–∫—ñ—Å—Ç—å –≤–∏—è–≤–ª–µ–Ω–∏—Ö —É—á–Ω—ñ–≤', fontsize=12, fontweight='bold')
    axes[0, 0].set_xlabel('–ß–∞—Å (—Å–µ–∫)')
    axes[0, 0].set_ylabel('–ö—ñ–ª—å–∫—ñ—Å—Ç—å')
    axes[0, 0].grid(True, alpha=0.3)
    axes[0, 0].set_ylim(bottom=0)

    # –ì—Ä–∞—Ñ—ñ–∫ 2: –ü—ñ–¥–Ω—è—Ç—ñ —Ä—É–∫–∏
    axes[0, 1].plot(times, hands_up, color='green', linewidth=2, marker='o', markersize=2)
    axes[0, 1].fill_between(times, hands_up, alpha=0.3, color='green')
    axes[0, 1].set_title('–ü—ñ–¥–Ω—è—Ç—ñ —Ä—É–∫–∏ (–∞–∫—Ç–∏–≤–Ω–∞ —É—á–∞—Å—Ç—å)', fontsize=12, fontweight='bold')
    axes[0, 1].set_xlabel('–ß–∞—Å (—Å–µ–∫)')
    axes[0, 1].set_ylabel('–ö—ñ–ª—å–∫—ñ—Å—Ç—å')
    axes[0, 1].grid(True, alpha=0.3)
    axes[0, 1].set_ylim(bottom=0)

    # –ì—Ä–∞—Ñ—ñ–∫ 3: –Ü–Ω–¥–µ–∫—Å —É–≤–∞–≥–∏ –∫–ª–∞—Å—É
    axes[0, 2].plot(times, attention_index, color='purple', linewidth=2.5)
    axes[0, 2].fill_between(times, attention_index, alpha=0.3, color='purple')
    axes[0, 2].axhline(y=0.7, color='green', linestyle='--', alpha=0.5, label='Attentive')
    axes[0, 2].axhline(y=0.5, color='orange', linestyle='--', alpha=0.5, label='Neutral')
    axes[0, 2].axhline(y=0.3, color='red', linestyle='--', alpha=0.5, label='Distracted')
    axes[0, 2].set_title('–Ü–Ω–¥–µ–∫—Å —É–≤–∞–≥–∏ –∫–ª–∞—Å—É (Class Attention)', fontsize=12, fontweight='bold')
    axes[0, 2].set_xlabel('–ß–∞—Å (—Å–µ–∫)')
    axes[0, 2].set_ylabel('–Ü–Ω–¥–µ–∫—Å (0-1)')
    axes[0, 2].grid(True, alpha=0.3)
    axes[0, 2].set_ylim(0, 1)
    axes[0, 2].legend(loc='lower right', fontsize=8)

    # –ì—Ä–∞—Ñ—ñ–∫ 4: –£–≤–∞–∂–Ω—ñ —É—á–Ω—ñ
    axes[1, 0].plot(times, attentive, color='green', linewidth=2, marker='o', markersize=2)
    axes[1, 0].fill_between(times, attentive, alpha=0.3, color='green')
    axes[1, 0].set_title('–£–≤–∞–∂–Ω—ñ —É—á–Ω—ñ (Attentive ‚â•0.70)', fontsize=12, fontweight='bold')
    axes[1, 0].set_xlabel('–ß–∞—Å (—Å–µ–∫)')
    axes[1, 0].set_ylabel('–ö—ñ–ª—å–∫—ñ—Å—Ç—å')
    axes[1, 0].grid(True, alpha=0.3)
    axes[1, 0].set_ylim(bottom=0)

    # –ì—Ä–∞—Ñ—ñ–∫ 5: –ù–µ—É–≤–∞–∂–Ω—ñ —Ç–∞ –≤—ñ–¥–≤–æ–ª—ñ–∫–∞—é—Ç—å—Å—è
    axes[1, 1].plot(times, inattentive, color='red', linewidth=2, marker='o', markersize=2, label='Inattentive')
    axes[1, 1].plot(times, distracted, color='orange', linewidth=2, marker='o', markersize=2, label='Distracted')
    axes[1, 1].fill_between(times, inattentive, alpha=0.2, color='red')
    axes[1, 1].fill_between(times, distracted, alpha=0.2, color='orange')
    axes[1, 1].set_title('–ù–µ—É–≤–∞–∂–Ω—ñ—Å—Ç—å —ñ –≤—ñ–¥–≤–æ–ª—ñ–∫–∞–Ω–Ω—è', fontsize=12, fontweight='bold')
    axes[1, 1].set_xlabel('–ß–∞—Å (—Å–µ–∫)')
    axes[1, 1].set_ylabel('–ö—ñ–ª—å–∫—ñ—Å—Ç—å')
    axes[1, 1].grid(True, alpha=0.3)
    axes[1, 1].set_ylim(bottom=0)
    axes[1, 1].legend(loc='upper right', fontsize=9)

    # –ì—Ä–∞—Ñ—ñ–∫ 6: –†–æ–∑–ø–æ–¥—ñ–ª —Å—Ç–∞–Ω—ñ–≤ (stacked area)
    axes[1, 2].stackplot(times, attentive, neutral, distracted, inattentive,
                        labels=['Attentive', 'Neutral', 'Distracted', 'Inattentive'],
                        colors=['green', 'yellow', 'orange', 'red'],
                        alpha=0.7)
    axes[1, 2].set_title('–†–æ–∑–ø–æ–¥—ñ–ª —Å—Ç–∞–Ω—ñ–≤ —É–≤–∞–≥–∏ –≤ —á–∞—Å—ñ', fontsize=12, fontweight='bold')
    axes[1, 2].set_xlabel('–ß–∞—Å (—Å–µ–∫)')
    axes[1, 2].set_ylabel('–ö—ñ–ª—å–∫—ñ—Å—Ç—å —É—á–Ω—ñ–≤')
    axes[1, 2].grid(True, alpha=0.3)
    axes[1, 2].legend(loc='upper left', fontsize=9)

    plt.tight_layout()
    plt.savefig('activity_statistics_scientific.png', dpi=300, bbox_inches='tight')
    print(" –ó–±–µ—Ä–µ–∂–µ–Ω–æ: activity_statistics_scientific.png")

    # ===== –ü–Ü–î–°–£–ú–ö–û–í–ê –°–¢–ê–¢–ò–°–¢–ò–ö–ê =====
    print("\n" + "="*70)
    print("üìä –ü–Ü–î–°–£–ú–ö–û–í–ê –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("="*70)
    
    total_time = max(times)
    total_minutes = int(total_time // 60)
    total_seconds = int(total_time % 60)
    
    print(f"  –¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –≤—ñ–¥–µ–æ: {total_time:.1f} —Å–µ–∫—É–Ω–¥ ({total_minutes}:{total_seconds:02d})")
    print(f" –û–±—Ä–æ–±–ª–µ–Ω–æ –∫–∞–¥—Ä—ñ–≤: {processed_frames}")
    print(f" –°–µ—Ä–µ–¥–Ω—ñ–π FPS –æ–±—Ä–æ–±–∫–∏: {processed_frames/total_time:.1f}")
    print(f" –°–µ—Ä–µ–¥–Ω—è –∫—ñ–ª—å–∫—ñ—Å—Ç—å —É—á–Ω—ñ–≤: {np.mean(visible):.1f}")
    print(f" –ú–∞–∫—Å–∏–º—É–º —É—á–Ω—ñ–≤ –Ω–∞ –µ–∫—Ä–∞–Ω—ñ: {max(visible)}")
    print()
    print(f" –°–µ—Ä–µ–¥–Ω—è –∫—ñ–ª—å–∫—ñ—Å—Ç—å —É–≤–∞–∂–Ω–∏—Ö: {np.mean(attentive):.2f}")
    print(f" –°–µ—Ä–µ–¥–Ω—è –∫—ñ–ª—å–∫—ñ—Å—Ç—å –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∏—Ö: {np.mean(neutral):.2f}")
    print(f" –°–µ—Ä–µ–¥–Ω—è –∫—ñ–ª—å–∫—ñ—Å—Ç—å –≤—ñ–¥–≤–æ–ª—ñ–∫–∞–Ω–∏—Ö: {np.mean(distracted):.2f}")
    print(f" –°–µ—Ä–µ–¥–Ω—è –∫—ñ–ª—å–∫—ñ—Å—Ç—å –Ω–µ—É–≤–∞–∂–Ω–∏—Ö: {np.mean(inattentive):.2f}")
    print()
    print(f" –í—Å—å–æ–≥–æ –ø—ñ–¥–Ω—è—Ç—Ç—ñ–≤ —Ä—É–∫: {sum(hands_up)}")
    print(f" –°–µ—Ä–µ–¥–Ω—è –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ø—ñ–¥–Ω—è—Ç–∏—Ö —Ä—É–∫: {np.mean(hands_up):.2f}")
    print(f" –ú–∞–∫—Å–∏–º—É–º –ø—ñ–¥–Ω—è—Ç–∏—Ö —Ä—É–∫ –æ–¥–Ω–æ—á–∞—Å–Ω–æ: {max(hands_up)}")
    print()
    print(f" –°–µ—Ä–µ–¥–Ω—ñ–π —ñ–Ω–¥–µ–∫—Å —É–≤–∞–≥–∏ –∫–ª–∞—Å—É: {np.mean(attention_index):.3f}")
    print(f" –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π —ñ–Ω–¥–µ–∫—Å —É–≤–∞–≥–∏: {min(attention_index):.3f}")
    print(f" –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∏–π —ñ–Ω–¥–µ–∫—Å —É–≤–∞–≥–∏: {max(attention_index):.3f}")
    print()
    
    # –í—ñ–¥—Å–æ—Ç–æ–∫ —á–∞—Å—É –≤ —Ä—ñ–∑–Ω–∏—Ö —Å—Ç–∞–Ω–∞—Ö
    if max(visible) > 0:
        total_student_time = sum(visible)
        pct_attentive = 100 * sum(attentive) / total_student_time
        pct_neutral = 100 * sum(neutral) / total_student_time
        pct_distracted = 100 * sum(distracted) / total_student_time
        pct_inattentive = 100 * sum(inattentive) / total_student_time
        
        print(" –†–û–ó–ü–û–î–Ü–õ –ß–ê–°–£ –£–í–ê–ì–ò:")
        print(f"   –£–≤–∞–∂–Ω—ñ: {pct_attentive:.1f}%")
        print(f"   –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ñ: {pct_neutral:.1f}%")
        print(f"   –í—ñ–¥–≤–æ–ª—ñ–∫–∞—é—Ç—å—Å—è: {pct_distracted:.1f}%")
        print(f"   –ù–µ—É–≤–∞–∂–Ω—ñ: {pct_inattentive:.1f}%")
    
    print("="*70)

    plt.show()
else:
    print("  –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –¥–ª—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤")


print("\nüéì –ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –≥—Ä–∞—Ñ—ñ–∫–∏ –¥–ª—è –¥–∏–ø–ª–æ–º–Ω–æ—ó —Ä–æ–±–æ—Ç–∏.")

